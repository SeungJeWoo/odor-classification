{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "# format: virtualflies x (PPL1_01, 02, .., 05, odor)\n",
    "# arranged odor #0 - #4\n",
    "virtualFly_PPL1 = scipy.io.loadmat('virtualFly_PPL1.mat')['virtualFly']\n",
    "virtualFly_MBON = scipy.io.loadmat('virtualFly_MBON.mat')['virtualFly_MBON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODOR_NUM = 5\n",
    "PPL1_NUM = 5\n",
    "MBON_NUM = 6\n",
    "NEURON_NUM = PPL1_NUM + MBON_NUM\n",
    "NUM_FLIES_PER_ODOR = 12\n",
    "\n",
    "\n",
    "VFP_OD1 = virtualFly_PPL1[:NUM_FLIES_PER_ODOR**PPL1_NUM,:]\n",
    "VFP_OD2 = virtualFly_PPL1[NUM_FLIES_PER_ODOR**PPL1_NUM:2*NUM_FLIES_PER_ODOR**PPL1_NUM,:]\n",
    "VFP_OD3 = virtualFly_PPL1[2*NUM_FLIES_PER_ODOR**PPL1_NUM:3*NUM_FLIES_PER_ODOR**PPL1_NUM,:]\n",
    "VFP_OD4 = virtualFly_PPL1[3*NUM_FLIES_PER_ODOR**PPL1_NUM:4*NUM_FLIES_PER_ODOR**PPL1_NUM,:]\n",
    "VFP_OD5 = virtualFly_PPL1[4*NUM_FLIES_PER_ODOR**PPL1_NUM:5*NUM_FLIES_PER_ODOR**PPL1_NUM,:]\n",
    "\n",
    "np.random.shuffle(VFP_OD1)\n",
    "np.random.shuffle(VFP_OD2)\n",
    "np.random.shuffle(VFP_OD3)\n",
    "np.random.shuffle(VFP_OD4)\n",
    "np.random.shuffle(VFP_OD5)\n",
    "\n",
    "VFM_OD1 = virtualFly_MBON[:NUM_FLIES_PER_ODOR**MBON_NUM,:]\n",
    "VFM_OD2 = virtualFly_MBON[NUM_FLIES_PER_ODOR**MBON_NUM:2*NUM_FLIES_PER_ODOR**MBON_NUM,:]\n",
    "VFM_OD3 = virtualFly_MBON[2*NUM_FLIES_PER_ODOR**MBON_NUM:3*NUM_FLIES_PER_ODOR**MBON_NUM,:]\n",
    "VFM_OD4 = virtualFly_MBON[3*NUM_FLIES_PER_ODOR**MBON_NUM:4*NUM_FLIES_PER_ODOR**MBON_NUM,:]\n",
    "VFM_OD5 = virtualFly_MBON[4*NUM_FLIES_PER_ODOR**MBON_NUM:5*NUM_FLIES_PER_ODOR**MBON_NUM,:]\n",
    "\n",
    "np.random.shuffle(VFM_OD1)\n",
    "np.random.shuffle(VFM_OD2)\n",
    "np.random.shuffle(VFM_OD3)\n",
    "np.random.shuffle(VFM_OD4)\n",
    "np.random.shuffle(VFM_OD5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining PPL1 + MBON\n",
    "\n",
    "numSamples = VFP_OD1.shape[0]\n",
    "VF_OD1 = np.concatenate((VFP_OD1[:,:PPL1_NUM], VFM_OD1[:numSamples,:]),axis=1)\n",
    "VF_OD2 = np.concatenate((VFP_OD2[:,:PPL1_NUM], VFM_OD2[:numSamples,:]),axis=1)\n",
    "VF_OD3 = np.concatenate((VFP_OD3[:,:PPL1_NUM], VFM_OD3[:numSamples,:]),axis=1)\n",
    "VF_OD4 = np.concatenate((VFP_OD4[:,:PPL1_NUM], VFM_OD4[:numSamples,:]),axis=1)\n",
    "VF_OD5 = np.concatenate((VFP_OD5[:,:PPL1_NUM], VFM_OD5[:numSamples,:]),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119744.0 (1119740, 12)\n",
      "62208.0 (62205, 12)\n",
      "62208.0 (62205, 12)\n",
      "Train shape:  (1119740, 11)\n",
      "Validation shape:  (62205, 11)\n",
      "Test shape:  (62205, 11)\n"
     ]
    }
   ],
   "source": [
    "# dataset arrange\n",
    "\n",
    "# based on PPL1 size\n",
    "numTrain = virtualFly_PPL1.shape[0] * 0.9\n",
    "numVal = virtualFly_PPL1.shape[0] * 0.05\n",
    "numTest = virtualFly_PPL1.shape[0] * 0.05\n",
    "numTrainPerOD = math.floor(numTrain/ODOR_NUM)\n",
    "numValPerOD = math.floor(numVal/ODOR_NUM)\n",
    "numTestPerOD = math.floor(numTest/ODOR_NUM)\n",
    "'''\n",
    "print(numTrain - numTrainPerOD*ODOR_NUM)\n",
    "print(numVal - numValPerOD*ODOR_NUM)\n",
    "print(numTest - numTestPerOD*ODOR_NUM)\n",
    "print(virtualFly.shape[0]/5 - numTrainPerOD - numValPerOD - numTestPerOD)\n",
    "print(numTrainPerOD, numValPerOD, numTestPerOD)\n",
    "'''\n",
    "mask = range(numTrainPerOD)\n",
    "trainSet = np.concatenate((VF_OD1[mask,:], VF_OD2[mask,:], VF_OD3[mask,:], VF_OD4[mask,:], VF_OD5[mask,:]),axis=0) \n",
    "np.random.shuffle(trainSet)\n",
    "X_train = trainSet[:,:NEURON_NUM]\n",
    "y_train = trainSet[:,-1]-1 # -1 to conform python index from 0 to 4 (class imported from MATLAB was from 1 to 5)\n",
    "X_train_shuffle = np.copy(X_train)\n",
    "np.random.shuffle(X_train_shuffle)\n",
    "\n",
    "mask = range(numTrainPerOD, numTrainPerOD+numValPerOD)\n",
    "valSet = np.concatenate((VF_OD1[mask,:], VF_OD2[mask,:], VF_OD3[mask,:], VF_OD4[mask,:], VF_OD5[mask,:]),axis=0) \n",
    "np.random.shuffle(valSet)\n",
    "X_val = valSet[:,:NEURON_NUM]\n",
    "y_val = valSet[:,-1]-1 # to conform python index format\n",
    "\n",
    "mask = range(numTrainPerOD+numValPerOD, numTrainPerOD+numValPerOD+numTestPerOD)\n",
    "testSet = np.concatenate((VF_OD1[mask,:], VF_OD2[mask,:], VF_OD3[mask,:], VF_OD4[mask,:], VF_OD5[mask,:]),axis=0) \n",
    "np.random.shuffle(testSet)\n",
    "X_test = testSet[:,:NEURON_NUM]\n",
    "y_test = testSet[:,-1]-1 # to conform python index format\n",
    "\n",
    "print(numTrain, trainSet.shape)\n",
    "print(numVal, valSet.shape)\n",
    "print(numTest, testSet.shape)\n",
    "\n",
    "print('Train shape: ', X_train.shape)\n",
    "print('Validation shape: ', X_val.shape)\n",
    "print('Test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.20979881  7.01952799 -0.05275849  2.77959281  8.1569809  18.50519541\n",
      "  5.17610824  5.768908    7.7611272  11.75774726 11.03249513] \n",
      " [ 6.55190598  6.6805451   5.11444378  6.89041502  3.84017398 13.52565991\n",
      "  9.80513404  7.38232189  8.4672489   7.56104869 12.28224976]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX_train /= std\\nX_val /= std\\nX_test /= std\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "#-mean - should do std as well?\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "print(mean,'\\n', std)\n",
    "\n",
    "X_train -= mean\n",
    "X_train_shuffle -= mean\n",
    "X_val -= mean\n",
    "X_test -= mean\n",
    "\n",
    "'''\n",
    "X_train /= std\n",
    "X_val /= std\n",
    "X_test /= std\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, XV, YV, model, lr, reg, batchSize, epoch):\n",
    "    X = torch.Tensor(X)\n",
    "    Y = torch.Tensor(Y)\n",
    "    #X = torch.FloatTensor(X)\n",
    "    #Y = torch.FloatTensor(Y)\n",
    "    N = len(Y)\n",
    "    XV = torch.FloatTensor(XV)\n",
    "    YV = torch.FloatTensor(YV)\n",
    "\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "   \n",
    "    for epoch in range(epoch):\n",
    "        perm = torch.randperm(N)\n",
    "        sum_loss = 0\n",
    "        model.train()\n",
    "        for i in range(0, N, batchSize):\n",
    "            x = X[perm[i:i+batchSize]]\n",
    "            y = Y[perm[i:i+batchSize]]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            weight = model.weight\n",
    "            bias = model.bias\n",
    "            output = model(x)\n",
    "            \n",
    "            #print(weight)\n",
    "            #print(bias)\n",
    "            #print(x)\n",
    "            #print(x.double() @ weight + bias.double())\n",
    "            #print(torch.mm(x, torch.t(model.weight))\n",
    "            #print(torch.addmm(bias, x, torch.t(weight)))\n",
    "            \n",
    "            '''\n",
    "            print(\"x:\",x)\n",
    "            print(\"y:\",y.long())\n",
    "            print(\"output:\",output)\n",
    "            '''\n",
    "            \n",
    "            correct_class_score = output[torch.arange(x.shape[0]), y.long()]\n",
    "            \n",
    "            margin = torch.maximum(torch.zeros(output.shape), output - correct_class_score.unsqueeze(1) + 1) # delta is 1\n",
    "            loss = (torch.sum(margin)-1*x.shape[0])/x.shape[0] # remove correct case when delta is 1\n",
    "            #print(\"loss1:\", loss)\n",
    "            loss += reg * torch.sum((weight.t() @ weight)) #/ 2.0\n",
    "            #print(\"loss2:\", loss)\n",
    "            \n",
    "            '''\n",
    "            print(output - correct_class_score.unsqueeze(1)+1)\n",
    "            print(torch.zeros(output.shape))\n",
    "            print(correct_class_score)\n",
    "            print(\"loss:\", loss)\n",
    "            '''\n",
    "            #loss = torch.mean(torch.clamp(1 - y * output, min=0))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += float(loss)\n",
    "            \n",
    "\n",
    "        print(\"Epoch: {:4d}\\tloss: {}\".format(epoch, sum_loss / N))\n",
    "\n",
    "        numScore = 0\n",
    "        model.eval()\n",
    "        for i in range(0, len(YV), batchSize):\n",
    "            x = XV[i:i+batchSize]\n",
    "            y = YV[i:i+batchSize]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                output = model(x).numpy()\n",
    "                pred = np.argmax(output, axis = 1)\n",
    "                #print(pred)\n",
    "                #print(y.numpy())\n",
    "                numScore += np.sum((pred == y.numpy()))\n",
    "                #print(numScore)\n",
    "            \n",
    "        \n",
    "        print(\"validation acuuracy: {}\".format(numScore / len(YV)))\n",
    "        \n",
    "def test(X, Y, model, batchSize, numOnly = False):\n",
    "    XT = torch.FloatTensor(X)\n",
    "    YT = torch.FloatTensor(Y)\n",
    "    numScore = 0\n",
    "    model.eval()\n",
    "    for i in range(0, len(YT), batchSize):\n",
    "        x = XT[i:i+batchSize]\n",
    "        y = YT[i:i+batchSize]\n",
    "        output = model(x).detach().numpy()\n",
    "        pred = np.argmax(output, axis = 1)\n",
    "        #print(pred)\n",
    "        #print(y.numpy())\n",
    "        numScore += np.sum((pred == y.numpy()))\n",
    "        #print(numScore)\n",
    "    if numOnly:\n",
    "        print(numScore / len(YT))\n",
    "    else:\n",
    "        print(\"test acuuracy: {}\".format(numScore / len(YT)))\n",
    "\n",
    "\n",
    "        \n",
    "def visualize(X, Y, model):\n",
    "    W = model.weight.squeeze().detach().cpu().numpy()\n",
    "    b = model.bias.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    delta = 0.001\n",
    "    x = np.arange(X[:, 0].min(), X[:, 0].max(), delta)\n",
    "    y = np.arange(X[:, 1].min(), X[:, 1].max(), delta)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    xy = list(map(np.ravel, [x, y]))\n",
    "\n",
    "    z = (W.dot(xy) + b).reshape(x.shape)\n",
    "    z[np.where(z > 1.0)] = 4\n",
    "    z[np.where((z > 0.0) & (z <= 1.0))] = 3\n",
    "    z[np.where((z > -1.0) & (z <= 0.0))] = 2\n",
    "    z[np.where(z <= -1.0)] = 1\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlim([X[:, 0].min() + delta, X[:, 0].max() - delta])\n",
    "    plt.ylim([X[:, 1].min() + delta, X[:, 1].max() - delta])\n",
    "    plt.contourf(x, y, z, alpha=0.8, cmap=\"Greys\")\n",
    "    plt.scatter(x=X[:, 0], y=X[:, 1], c=\"black\", s=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0\tloss: 0.005266073258307197\n",
      "validation acuuracy: 0.8140181657423037\n",
      "Epoch:    1\tloss: 0.0025509063469651813\n",
      "validation acuuracy: 0.8167349891487823\n",
      "Epoch:    2\tloss: 0.0024806035194266324\n",
      "validation acuuracy: 0.8176352383248935\n",
      "Epoch:    3\tloss: 0.0024649123392121797\n",
      "validation acuuracy: 0.8167832167832167\n",
      "Epoch:    4\tloss: 0.0024598902128346064\n",
      "validation acuuracy: 0.8175870106904589\n",
      "Epoch:    5\tloss: 0.002458084295791491\n",
      "validation acuuracy: 0.8172172654931276\n",
      "Epoch:    6\tloss: 0.002457498122510817\n",
      "validation acuuracy: 0.8172654931275621\n",
      "Epoch:    7\tloss: 0.0024574468124208136\n",
      "validation acuuracy: 0.8160598022666988\n",
      "Epoch:    8\tloss: 0.002457175517654126\n",
      "validation acuuracy: 0.8170404308335343\n",
      "Epoch:    9\tloss: 0.0024569876315696476\n",
      "validation acuuracy: 0.8170243549553894\n",
      "test acuuracy: 0.8153846153846154\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0005\n",
    "reg = 0.0001\n",
    "\n",
    "batchSize = 200\n",
    "epoch = 10\n",
    "    \n",
    "model = nn.Linear(11, 5)\n",
    "\n",
    "train(X_train, y_train, X_val, y_val, model, lr, reg, batchSize, epoch)\n",
    "test(X_test, y_test, model, batchSize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle Begins\n",
      "Epoch:    0\tloss: 0.021941065794443815\n",
      "validation acuuracy: 0.1725745518848967\n",
      "Epoch:    1\tloss: 0.020003890174863544\n",
      "validation acuuracy: 0.16159472711196848\n",
      "Epoch:    2\tloss: 0.020007618134899045\n",
      "validation acuuracy: 0.22618760549795033\n",
      "Epoch:    3\tloss: 0.02000186104376479\n",
      "validation acuuracy: 0.21213728799935697\n",
      "Epoch:    4\tloss: 0.02000156281741222\n",
      "validation acuuracy: 0.20196125713367094\n",
      "Epoch:    5\tloss: 0.019999414320738318\n",
      "validation acuuracy: 0.24314765694076038\n",
      "Epoch:    6\tloss: 0.020002845487181193\n",
      "validation acuuracy: 0.12463628325697292\n",
      "Epoch:    7\tloss: 0.020005708114506422\n",
      "validation acuuracy: 0.1628164938509766\n",
      "Epoch:    8\tloss: 0.020004477720354137\n",
      "validation acuuracy: 0.15963346997829755\n",
      "Epoch:    9\tloss: 0.020011596193200663\n",
      "validation acuuracy: 0.2561048147255044\n",
      "test acuuracy: 0.2544650751547303\n"
     ]
    }
   ],
   "source": [
    "print(\"Shuffle Begins\")\n",
    "model_shuffle = nn.Linear(11,5);\n",
    "train(X_train_shuffle, y_train, X_val, y_val, model_shuffle, lr, reg, batchSize, epoch)\n",
    "test(X_test, y_test, model_shuffle, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62205, 12)\n",
      "(62205, 12)\n",
      "(124410, 12)\n",
      "(124410, 11)\n",
      "(124410,)\n"
     ]
    }
   ],
   "source": [
    "print(valSet.shape)\n",
    "print(testSet.shape)\n",
    "fullTestSet = np.concatenate((valSet,testSet),axis=0)\n",
    "print(fullTestSet.shape)\n",
    "np.random.shuffle(fullTestSet)\n",
    "X_fullTest = fullTestSet[:,:NEURON_NUM]\n",
    "y_fullTest = fullTestSet[:,-1]-1 # to conform python index format\n",
    "print(X_fullTest.shape)\n",
    "print(y_fullTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = range(numTrainPerOD, numTrainPerOD+numValPerOD+numTestPerOD)\n",
    "fullTestSet2 = np.concatenate((VF_OD1[mask,:], VF_OD2[mask,:], VF_OD3[mask,:], VF_OD4[mask,:], VF_OD5[mask,:]),axis=0) \n",
    "\n",
    "#np.random.shuffle(fullTestSet2)\n",
    "X_val = valSet[:,:NEURON_NUM]\n",
    "y_val = valSet[:,-1]-1 # to conform python index format\n",
    "\n",
    "X_fullTestSet2 = testSet[:,:NEURON_NUM]\n",
    "y_fullTestSet2 = testSet[:,-1]-1 # to conform python index format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822\n",
      "0.816\n",
      "0.813\n",
      "0.801\n",
      "0.833\n",
      "0.815\n",
      "0.82\n",
      "0.825\n",
      "0.812\n",
      "0.809\n",
      "0.827\n",
      "0.804\n",
      "0.816\n",
      "0.809\n",
      "0.827\n",
      "0.823\n",
      "0.821\n",
      "0.827\n",
      "0.803\n",
      "0.807\n",
      "0.81\n",
      "0.785\n",
      "0.824\n",
      "0.816\n",
      "0.8\n",
      "0.821\n",
      "0.811\n",
      "0.811\n",
      "0.82\n",
      "0.837\n",
      "0.842\n",
      "0.818\n",
      "0.812\n",
      "0.827\n",
      "0.811\n",
      "0.814\n",
      "0.829\n",
      "0.815\n",
      "0.818\n",
      "0.813\n",
      "0.818\n",
      "0.787\n",
      "0.81\n",
      "0.823\n",
      "0.83\n",
      "0.836\n",
      "0.812\n",
      "0.801\n",
      "0.828\n",
      "0.786\n",
      "0.819\n",
      "0.838\n",
      "0.824\n",
      "0.813\n",
      "0.828\n",
      "0.813\n",
      "0.813\n",
      "0.814\n",
      "0.821\n",
      "0.82\n",
      "0.833\n",
      "0.826\n",
      "0.803\n",
      "0.811\n",
      "0.833\n",
      "0.807\n",
      "0.835\n",
      "0.828\n",
      "0.804\n",
      "0.821\n",
      "0.819\n",
      "0.805\n",
      "0.839\n",
      "0.829\n",
      "0.828\n",
      "0.827\n",
      "0.801\n",
      "0.829\n",
      "0.81\n",
      "0.824\n",
      "0.821\n",
      "0.805\n",
      "0.823\n",
      "0.821\n",
      "0.822\n",
      "0.816\n",
      "0.803\n",
      "0.807\n",
      "0.798\n",
      "0.793\n",
      "0.797\n",
      "0.817\n",
      "0.781\n",
      "0.797\n",
      "0.822\n",
      "0.813\n",
      "0.825\n",
      "0.819\n",
      "0.819\n",
      "0.818\n",
      "0.826\n",
      "0.797\n",
      "0.816\n",
      "0.791\n",
      "0.818\n",
      "0.817\n",
      "0.803\n",
      "0.82\n",
      "0.815\n",
      "0.817\n",
      "0.831\n",
      "0.822\n",
      "0.797\n",
      "0.831\n",
      "0.806\n",
      "0.818\n",
      "0.82\n",
      "0.823\n",
      "0.804\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "sampleSize = 1000\n",
    "\n",
    "#test for 120 cases\n",
    "for i in range (0,120,1):\n",
    "    test(X_fullTest[i*sampleSize:(i+1)*sampleSize,:], y_fullTest[i*sampleSize:(i+1)*sampleSize], model, batchSize, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.269\n",
      "0.25\n",
      "0.244\n",
      "0.244\n",
      "0.238\n",
      "0.271\n",
      "0.277\n",
      "0.232\n",
      "0.247\n",
      "0.281\n",
      "0.242\n",
      "0.266\n",
      "0.272\n",
      "0.272\n",
      "0.235\n",
      "0.27\n",
      "0.264\n",
      "0.257\n",
      "0.242\n",
      "0.243\n",
      "0.254\n",
      "0.265\n",
      "0.247\n",
      "0.246\n",
      "0.237\n",
      "0.268\n",
      "0.258\n",
      "0.253\n",
      "0.275\n",
      "0.254\n",
      "0.265\n",
      "0.266\n",
      "0.218\n",
      "0.237\n",
      "0.242\n",
      "0.267\n",
      "0.261\n",
      "0.277\n",
      "0.274\n",
      "0.278\n",
      "0.246\n",
      "0.252\n",
      "0.232\n",
      "0.252\n",
      "0.244\n",
      "0.255\n",
      "0.264\n",
      "0.227\n",
      "0.254\n",
      "0.225\n",
      "0.256\n",
      "0.267\n",
      "0.268\n",
      "0.257\n",
      "0.247\n",
      "0.235\n",
      "0.263\n",
      "0.236\n",
      "0.272\n",
      "0.25\n",
      "0.27\n",
      "0.257\n",
      "0.266\n",
      "0.24\n",
      "0.273\n",
      "0.246\n",
      "0.247\n",
      "0.27\n",
      "0.244\n",
      "0.263\n",
      "0.266\n",
      "0.262\n",
      "0.281\n",
      "0.274\n",
      "0.254\n",
      "0.267\n",
      "0.24\n",
      "0.267\n",
      "0.245\n",
      "0.249\n",
      "0.237\n",
      "0.279\n",
      "0.243\n",
      "0.257\n",
      "0.254\n",
      "0.244\n",
      "0.259\n",
      "0.246\n",
      "0.237\n",
      "0.23\n",
      "0.27\n",
      "0.257\n",
      "0.256\n",
      "0.273\n",
      "0.256\n",
      "0.259\n",
      "0.245\n",
      "0.256\n",
      "0.285\n",
      "0.25\n",
      "0.259\n",
      "0.273\n",
      "0.28\n",
      "0.251\n",
      "0.248\n",
      "0.257\n",
      "0.256\n",
      "0.292\n",
      "0.234\n",
      "0.248\n",
      "0.254\n",
      "0.271\n",
      "0.239\n",
      "0.282\n",
      "0.237\n",
      "0.256\n",
      "0.244\n",
      "0.259\n",
      "0.248\n",
      "0.242\n"
     ]
    }
   ],
   "source": [
    "sampleSize = 1000\n",
    "\n",
    "#test for 120 cases\n",
    "for i in range (0,120,1):\n",
    "    test(X_fullTest[i*sampleSize:(i+1)*sampleSize,:], y_fullTest[i*sampleSize:(i+1)*sampleSize], model_shuffle, batchSize, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
